{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## San-Franscisco Crime Predition Challenge - Kaggle\n",
    "### Team Member : Shanti Greene, Jing Xu, Abhishek Kumar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Description\n",
    "\n",
    "This dataset contains incidents derived from SFPD Crime Incident Reporting system. The data ranges from 1/1/2003 to 5/13/2015. The training set and test set rotate every week, meaning week 1,3,5,7... belong to test set, week 2,4,6,8 belong to training set. \n",
    "\n",
    "##### train.csv / test.csv\n",
    "\n",
    "Data fields \n",
    "\n",
    " - Dates - timestamp of the crime incident \n",
    " - Category - category of the crime incident (only in train.csv). This is the target variable you are going to predict. \n",
    " - Descript - detailed description of the crime incident (only in train.csv) \n",
    " - DayOfWeek - the day of the week \n",
    " - PdDistrict - name of the Police Department District \n",
    " - Resolution - how the crime incident was resolved (only in train.csv) \n",
    " - Address - the approximate street address of the crime incident  \n",
    " - X - Longitude \n",
    " - Y - Latitude\n",
    " \n",
    "##### Submission data ( sampleSubmission.csv)\n",
    "\n",
    "You must submit a csv file with the incident id, all candidate class names, and a probability for each class. The order of the rows does not matter. The file must have a header and should look like the following:\n",
    "\n",
    "\n",
    "##### evaluation criteria\n",
    "\n",
    "Submissions are evaluated using the multi-class logarithmic loss. Each incident has been labeled with one true class. For each incident, you must submit a set of predicted probabilities (one for every class). The formula is then,\n",
    "\n",
    "logloss=−1/N∑i=1 to N ∑ j=1 to M yijlog(pij),\n",
    "\n",
    "where N is the number of images in the test set, M is the number of class labels, log is the natural logarithm, yij is 1 if observation i is in class j and 0 otherwise, and pij is the predicted probability that observation i belongs to class j.\n",
    "\n",
    "The submitted probabilities for a given incident are not required to sum to one because they are rescaled prior to being scored (each row is divided by the row sum). In order to avoid the extremes of the log function, predicted probabilities are replaced with max(min(p,1−10−15),10−15).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Force matplotlib to not use any Xwindows backend.\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read train and test data files\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "#submission_df = pd.read_csv('sampleSubmission.csv')\n",
    "#street_df = pd.read_csv('Street_Names.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 2015-05-13 23:53:00</td>\n",
       "      <td>       WARRANTS</td>\n",
       "      <td>           WARRANT ARREST</td>\n",
       "      <td> Wednesday</td>\n",
       "      <td> NORTHERN</td>\n",
       "      <td> ARREST, BOOKED</td>\n",
       "      <td>        OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td> 37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2015-05-13 23:53:00</td>\n",
       "      <td> OTHER OFFENSES</td>\n",
       "      <td> TRAFFIC VIOLATION ARREST</td>\n",
       "      <td> Wednesday</td>\n",
       "      <td> NORTHERN</td>\n",
       "      <td> ARREST, BOOKED</td>\n",
       "      <td>        OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td> 37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2015-05-13 23:33:00</td>\n",
       "      <td> OTHER OFFENSES</td>\n",
       "      <td> TRAFFIC VIOLATION ARREST</td>\n",
       "      <td> Wednesday</td>\n",
       "      <td> NORTHERN</td>\n",
       "      <td> ARREST, BOOKED</td>\n",
       "      <td> VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td> 37.800414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates        Category                  Descript  DayOfWeek  \\\n",
       "0  2015-05-13 23:53:00        WARRANTS            WARRANT ARREST  Wednesday   \n",
       "1  2015-05-13 23:53:00  OTHER OFFENSES  TRAFFIC VIOLATION ARREST  Wednesday   \n",
       "2  2015-05-13 23:33:00  OTHER OFFENSES  TRAFFIC VIOLATION ARREST  Wednesday   \n",
       "\n",
       "  PdDistrict      Resolution                    Address           X          Y  \n",
       "0   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST -122.425892  37.774599  \n",
       "1   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST -122.425892  37.774599  \n",
       "2   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST -122.424363  37.800414  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show head of train_df\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data Visualization, Crime Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create Map of crimes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mapdata = np.loadtxt(\"sf_map_copyright_openstreetmap_contributors.txt\")\n",
    "plt.imshow(mapdata, cmap = plt.get_cmap('gray'))\n",
    "plt.savefig('map.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-217b878a31c1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-217b878a31c1>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    echo $DISPLAY\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "echo $DISPLAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Crime density plots setup\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "train_m = train_df\n",
    "#Get rid of the bad lat/longs\n",
    "train_m['Xok'] = train_m[train_m.X<-121].X\n",
    "train_m['Yok'] = train_m[train_m.Y<40].Y\n",
    "train_m = train_m.dropna()\n",
    "#select 350,000 random rows, it gets real slow with more rows\n",
    "rows = np.random.choice(train_m.index.values, 350000)\n",
    "sampled_df = train_m.ix[rows]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of observations must be larger than the number of variables.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-19f62d186944>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlon_lat_box\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0masp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#add the density plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Xok\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Yok\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclipsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Reds\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshade\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./sf_crime_density1.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sgreene/anaconda/lib/python2.7/site-packages/seaborn/axisgrid.pyc\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m             \u001b[1;31m# Draw the plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_facet_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[1;31m# Finalize the annotations and layout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sgreene/anaconda/lib/python2.7/site-packages/seaborn/axisgrid.pyc\u001b[0m in \u001b[0;36m_facet_plot\u001b[1;34m(self, func, ax, plot_args, plot_kwargs)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;31m# Draw the plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mplot_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplot_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;31m# Sort out the supporting information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sgreene/anaconda/lib/python2.7/site-packages/seaborn/distributions.pyc\u001b[0m in \u001b[0;36mkdeplot\u001b[1;34m(data, data2, shade, vertical, kernel, bw, gridsize, cut, clip, legend, ax, cumulative, **kwargs)\u001b[0m\n\u001b[0;32m    860\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbivariate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m         ax = _bivariate_kdeplot(x, y, shade, kernel, bw, gridsize,\n\u001b[1;32m--> 862\u001b[1;33m                                 cut, clip, legend, ax, **kwargs)\n\u001b[0m\u001b[0;32m    863\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         ax = _univariate_kdeplot(data, shade, vertical, kernel, bw,\n",
      "\u001b[1;32m/home/sgreene/anaconda/lib/python2.7/site-packages/seaborn/distributions.pyc\u001b[0m in \u001b[0;36m_bivariate_kdeplot\u001b[1;34m(x, y, filled, kernel, bw, gridsize, cut, clip, axlabel, ax, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[1;31m# Calculate the KDE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_has_statsmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         \u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_statsmodels_bivariate_kde\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgridsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_scipy_bivariate_kde\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgridsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sgreene/anaconda/lib/python2.7/site-packages/seaborn/distributions.pyc\u001b[0m in \u001b[0;36m_statsmodels_bivariate_kde\u001b[1;34m(x, y, bw, gridsize, cut, clip)\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m     \u001b[0mkde\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonparametric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKDEMultivariate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m     \u001b[0mx_support\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_kde_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgridsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[0my_support\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_kde_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgridsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sgreene/anaconda/lib/python2.7/site-packages/statsmodels/nonparametric/kernel_density.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, var_type, bw, defaults)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnobs\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             raise ValueError(\"The number of observations must be larger \" \\\n\u001b[0m\u001b[0;32m    112\u001b[0m                              \"than the number of variables.\")\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of observations must be larger than the number of variables."
     ]
    }
   ],
   "source": [
    "#Crime density plots\n",
    "\n",
    "# Supplied map bounding box:\n",
    "#    ll.lon     ll.lat   ur.lon     ur.lat\n",
    "#    -122.52469 37.69862 -122.33663 37.82986\n",
    "mapdata = np.loadtxt(\"sf_map_copyright_openstreetmap_contributors.txt\")\n",
    "asp = mapdata.shape[0] * 1.0 / mapdata.shape[1]\n",
    "lon_lat_box = (-122.5247, -122.3366, 37.699, 37.8299)\n",
    "clipsize = [[-122.5247, -122.3366],[ 37.699, 37.8299]]\n",
    "\n",
    "#Seaborn FacetGrid, split by crime Category\n",
    "g=sns.FacetGrid(sampled_df, col=\"Category\", col_wrap=6, size=5, aspect=1/asp)\n",
    "\n",
    "#add the background map\n",
    "for ax in g.axes:\n",
    "    ax.imshow(mapdata, cmap=plt.get_cmap('gray'), extent=lon_lat_box, aspect=asp)\n",
    "#add the density plot\n",
    "g.map(sns.kdeplot, \"Xok\", \"Yok\", clip=clipsize, cmap=\"Reds\", shade=False)\n",
    "plt.savefig('./sf_crime_density1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data Manipulation, Make X,Y Squares and assign midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sgreene/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sgreene/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 877982 entries, 0 to 878048\n",
      "Data columns (total 13 columns):\n",
      "Dates         877982 non-null object\n",
      "Category      877982 non-null object\n",
      "Descript      877982 non-null object\n",
      "DayOfWeek     877982 non-null object\n",
      "PdDistrict    877982 non-null object\n",
      "Resolution    877982 non-null object\n",
      "Address       877982 non-null object\n",
      "X             877982 non-null float64\n",
      "Y             877982 non-null float64\n",
      "Xok           877982 non-null float64\n",
      "Yok           877982 non-null float64\n",
      "Xmidcoord     877982 non-null float64\n",
      "Ymidcoord     877982 non-null float64\n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 93.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#take a dataset and make squares for crime blocks, return dataset with appended data\n",
    "def make_geosquares (dataset, nparts):\n",
    "    #Get min and max of the valid lats and longs\n",
    "    Xcoord = np.asarray(dataset['Xok'])\n",
    "    Ycoord = np.asarray(dataset['Yok'])\n",
    "    Xmin = np.amin(Xcoord)\n",
    "    Xmax = np.amax(Xcoord)\n",
    "    Ymin = np.amin(Ycoord)\n",
    "    Ymax = np.amax(Ycoord)\n",
    "    #find the top left corner and center point for each square and assign to array\n",
    "    Xdist = (Xmax - Xmin)/nparts\n",
    "    Ydist = (Ymax - Ymin)/nparts\n",
    "    Xtopleft = np.empty(nparts)\n",
    "    Ytopleft = np.empty(nparts)\n",
    "    Xmid = np.empty(nparts)\n",
    "    Ymid = np.empty(nparts)\n",
    "    for i in range (nparts):\n",
    "        Xtopleft[i] = Xmin + (i * Xdist)\n",
    "        Xmid[i] = Xmin + (i * Xdist / 2)\n",
    "        Ytopleft[i] = Ymin + (i * Ydist)\n",
    "        Ymid[i] = Ymin + (i * Ydist / 2)\n",
    "    #go thru the X and Y coords and assign to squares based on top left, assign value of middle of square\n",
    "    Xbin = np.digitize(Xcoord, Xtopleft, right=False)\n",
    "    Ybin = np.digitize(Ycoord, Ytopleft, right=False)\n",
    "    Xmidcoord = np.empty(len(Xcoord))\n",
    "    Ymidcoord = np.empty(len(Ycoord))\n",
    "    for i in range(len(dataset)):\n",
    "        Xmidcoord[i] = Xmid[Xbin[i]-1]\n",
    "        Ymidcoord[i] = Ymid[Ybin[i]-1]\n",
    "    dataset['Xmidcoord'] = Xmidcoord\n",
    "    dataset['Ymidcoord'] = Ymidcoord\n",
    "    return dataset\n",
    "train_sq = make_geosquares(train_m,20)\n",
    "print train_sq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Make top crime squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the top description and category by square\n",
    "def top_crime_square(dataset):\n",
    "    X = np.unique(np.asarray(dataset['Xmidcoord']))\n",
    "    Y = np.unique(np.asarray(dataset['Ymidcoord']))\n",
    "    Xmid = np.asarray(dataset['Xmidcoord'])\n",
    "    Ymid = np.asarray(dataset['Ymidcoord'])\n",
    "    XYindex = np.empty(len(dataset))\n",
    "    for i in range(len(Xmid)):\n",
    "        x = np.argwhere(X == Xmid[i])\n",
    "        y = np.argwhere(Y == Ymid[i])\n",
    "        XYindex[i] = (x[0,0]*len(Y)) + y[0,0]\n",
    "    dataset['XYIndex'] = XYindex\n",
    "    aCoord = np.empty([(len(X)*len(Y)),3])\n",
    "    k = 0;\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(Y)):\n",
    "            aCoord[k][0] = X[i]\n",
    "            aCoord[k][1] = Y[j]\n",
    "            aCoord[k][2] = k\n",
    "            k += 1\n",
    "    aCategory = []\n",
    "    aDescription = []\n",
    "    for i in range(len(aCoord)):\n",
    "        id = dataset[dataset['XYIndex'] == aCoord[i][2]].Category.value_counts()[:1].index\n",
    "        aCategory.append(str(id)[str(id).find('[')+3: str(id).find(']')-1])\n",
    "        id2 = dataset[dataset['XYIndex'] == aCoord[i][2]].Descript.value_counts()[:1].index\n",
    "        aDescription.append(str(id)[str(id).find('[')+3: str(id).find(']')-1])\n",
    "    CrimeSquare = pd.DataFrame(data=aCoord,columns = [\"X\",\"Y\",\"XYIndex\"])\n",
    "    CrimeSquare['Category'] = aCategory\n",
    "    CrimeSquare['Description'] = aDescription\n",
    "    return CrimeSquare\n",
    "\n",
    "#map the description and category by square\n",
    "def viz_crime_square(dataset):\n",
    "    #show background map\n",
    "    mapdata = np.loadtxt(\"./sf_map_copyright_openstreetmap_contributors.txt\")\n",
    "    asp = mapdata.shape[0] * 1.0 / mapdata.shape[1]\n",
    "    lon_lat_box = (-122.5247, -122.3366, 37.699, 37.8299)\n",
    "    clipsize = [[-122.5247, -122.3366],[ 37.699, 37.8299]]\n",
    "    g = sns.PairGrid(dataset, x_vars=\"X\", y_vars=\"Y\", hue=\"Category\")\n",
    "    plt.imshow(mapdata, cmap=plt.get_cmap('gray'), extent=lon_lat_box, aspect=asp)\n",
    "    g.map(plt.scatter)\n",
    "    plt.savefig('./testmap.png')\n",
    "    \n",
    "#train_sq = make_geosquares(train_m,50)\n",
    "#csquare = top_crime_square(train_sq)\n",
    "viz_crime_square(csquare)\n",
    "#csquare.to_csv('./vizme.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Address Suffixes or maybe sufficies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['al', 'mar', 'ex', 'av', 'cr', 'ter', 'i-80', 'ct', 'rw', 'ln', 'tr', 'stwy', 'rd', 'way', 'pl', 'hy', 'palms', 'bl', 'park', 'wk', 'i-280', 'hwy', 'ferlinghetti', 'dr', 'wy', 'bufano', 'st', 'pz'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Suffixes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 2015-05-13 23:53:00</td>\n",
       "      <td>       WARRANTS</td>\n",
       "      <td>               WARRANT ARREST</td>\n",
       "      <td> Wednesday</td>\n",
       "      <td> NORTHERN</td>\n",
       "      <td> ARREST, BOOKED</td>\n",
       "      <td>        OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td> 37.774599</td>\n",
       "      <td> st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2015-05-13 23:53:00</td>\n",
       "      <td> OTHER OFFENSES</td>\n",
       "      <td>     TRAFFIC VIOLATION ARREST</td>\n",
       "      <td> Wednesday</td>\n",
       "      <td> NORTHERN</td>\n",
       "      <td> ARREST, BOOKED</td>\n",
       "      <td>        OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td> 37.774599</td>\n",
       "      <td> st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2015-05-13 23:33:00</td>\n",
       "      <td> OTHER OFFENSES</td>\n",
       "      <td>     TRAFFIC VIOLATION ARREST</td>\n",
       "      <td> Wednesday</td>\n",
       "      <td> NORTHERN</td>\n",
       "      <td> ARREST, BOOKED</td>\n",
       "      <td> VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td> 37.800414</td>\n",
       "      <td> st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2015-05-13 23:30:00</td>\n",
       "      <td>  LARCENY/THEFT</td>\n",
       "      <td> GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td> Wednesday</td>\n",
       "      <td> NORTHERN</td>\n",
       "      <td>           NONE</td>\n",
       "      <td>  1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td> 37.800873</td>\n",
       "      <td> st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 2015-05-13 23:30:00</td>\n",
       "      <td>  LARCENY/THEFT</td>\n",
       "      <td> GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td> Wednesday</td>\n",
       "      <td>     PARK</td>\n",
       "      <td>           NONE</td>\n",
       "      <td> 100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td> 37.771541</td>\n",
       "      <td> st</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates        Category                      Descript  \\\n",
       "0  2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1  2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2  2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3  2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "4  2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y Suffixes  \n",
       "0 -122.425892  37.774599       st  \n",
       "1 -122.425892  37.774599       st  \n",
       "2 -122.424363  37.800414       st  \n",
       "3 -122.426995  37.800873       st  \n",
       "4 -122.438738  37.771541       st  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def address_suffix (dataset):\n",
    "    aSuffix = []\n",
    "    for i in range(0,len(dataset)):\n",
    "        suf = str(dataset['Address'][i]).lower().rsplit(\" \",1)[-1]\n",
    "        if suf == \"/\":\n",
    "            suf = (str(dataset['Address'][i]).lower().rsplit(\" \",1)[0]).rsplit(\" \",1)[-1]\n",
    "        aSuffix.append(suf)\n",
    "    suffix = pd.DataFrame(aSuffix,columns=['Suffixes'])\n",
    "    dataset['Suffixes'] = suffix['Suffixes']\n",
    "    print set(aSuffix)\n",
    "    return dataset\n",
    "x = address_suffix(train_df)\n",
    "x.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
